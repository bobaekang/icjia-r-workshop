---
title: "R Workshop: Module 5 (1)"
author: "Bobae Kang"
date: "April 18, 2018"
output:
  html_document:
    self_contained: false
    lib_dir: ./notes_files
    toc: TRUE
    toc_float	:	TRUE
    toc_depth: 2
    includes:
      after_body: ../include_footer.html
css: ../css/style.css
---
<!-- fontawesome CDN -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<!-- logo -->
<div class="logo">
  <a href="http://www.icjia.state.il.us/"><img src="../images/icjia.png" alt="ICJIA logo"></img></a>
</div>


```{r setup, include=FALSE}
library(knitr)
library(dplyr)
library(icjiar)
library(broom)
library(modelr)
opts_chunk$set(echo = TRUE)
```

This page contains the notes for **the first part of R Workshop Module 5: Statistical modeling with R**, which is part of the R Workshop series prepared by ICJIA Research Analyst [Bobae Kang](http://www.icjia.state.il.us/biographies/bobae-kang) to enable and encourage ICJIA researchers to take advantage of R, a statistical programming language that is one of the most powerful modern research tools.

### Links
Click [**here**](../index.html) to go to the workshop **home page**.

Click [**here**](../modules.html) to go to the workshop **Modules page**.

Click [**here**](../slides/module5_slides1.html) to view the accompanying **slides for Module 5, Part 1**.

Navigate to the other workshop materials:

<button class="btn" data-toggle="collapse" data-target="#collapse-navigate" aria-expanded="false" aria-controls="collapse-navigate">**SEE MORE**</button>

<div class="collapse mt-1" id="collapse-navigate">
<div style="padding:20px;">

* **Module 1: Introduction to R** ([**slides**](../slides/module1_slides.html),
[**note**](module1_notes.html))
* **Module 2: R basics**
    * Part 1 ([**slides**](../slides/module2_slides1.html), [**note**](module2_notes1.html))
    * Part 2 ([**slides**](../slides/module2_slides2.html), [**note**](module2_notes2.html))
* **Module 3: Data analysis with R**
    * Part 1 ([**slides**](../slides/module3_slides1.html), [**note**](module3_notes1.html))
    * Part 2 ([**slides**](../slides/module3_slides2.html), [**note**](module3_notes2.html))
* **Module 4: Data visualization with R**
    * Part 1 ([**slides**](../slides/module4_slides1.html), [**note**](module4_notes1.html))
    * Part 2 ([**slides**](../slides/module4_slides2.html), [**note**](module4_notes2.html))
* **Module 5: Statistical modeling with R**
    * Part 2 ([**slides**](../slides/module5_slides2.html), [**note**](module5_notes2.html))
* **Module 6: "To Infinity and Beyond"**
    * Part 1 ([**slides**](../slides/module6_slides1.html), [**note**](module6_notes1.html))
    * Part 2 ([**slides**](../slides/module6_slides2.html), [**note**](module6_notes2.html))

</div>
</div>


***


# Statistical modleing with R (1): Basics of statistical modeling

R is first designed as a programming language and an environment for statistics and data analysis. Accordingly, R provides as part of its base packages a host of handy tools for conducting statistical analysis. This part introduces the basics of descriptive and inferential statistics in R and touches on fitting linear and generalized linear models.


***


# Basic Descriptive Statistics
```{r echo=FALSE, out.width="50%", out.extra='style="display: block; margin: auto; box-shadow: none;"'}
include_graphics("../images/vadlo_descriptive_statistics.gif")
```
<p style="font-size:0.5em; text-align:center; color: #777;">
Source: <a href="http://vadlo.com/cartoons.php?id=196">Vadlo.com</a>
</p>


## Quick summary stats
```{r eval=FALSE}
summary(data)
```
The Base R `summary()` function is a quick way to get descriptive statistics on each columan of a tabular data object.

For numerical columns, we get the minimum, 1st quartile, median, mean, 3rd quartie and maximum values, as well as the count of missing value (`NA`).

For categorical variables (e.g. `factor`), we can the count for each level as well as the missing value (`NA`).

`summary()` is also used to get the "summary" of a fitted model object (e.g. `lm`) as well, as we will see shortly.

### Example
Let's take a look at `summary` of the `ispcrime` dataset.
```{r}
summary(ispcrime)
```


## Numerical variables
A distribution of numerical values can be described using statistics on the following characteristics:

* Central tendency
* Variability
* Shape
* Outliers

In the following, we will briefly discuss what each of these characteristics means and how we can get relevant statistics in R. 

### Central tendency
In statistics, central tendency is concerned with the "center" of a distribution. The following three are the common measures of central tendency:

* "mean" for the arithmetic mean
* "median" for the 50th percentile
* "mode" for the most frequent value

R has built-in functions for the first two: `mean()` and `median()`. Unfortunately, there is no native R function for mode. However, it is possible to create a custom function using the definition, i.e. the most frequnt value. Also, check out the `modeest` package that offers mode estimators.

Let us try using `mean()` and `median()` for the `violentCrime` column. And the result is ...
```{r}
mean(ispcrime$violentCrime)
median(ispcrime$violentCrime)
```
... wait, what? We get `NA` for both values.

This is because `NA` in R is a "contagious" value, making any operation with missing values return `NA`. To remedy this, we can use the `na.rm` argument, which takes a boolean input to control weather whether `NA` values are removed/excluded in calculation. The default is `na.rm = FALSE`

We try again with `na.rm = TRUE`:
```{r}
mean(ispcrime$violentCrime, na.rm = TRUE)
median(ispcrime$violentCrime, na.rm = TRUE)
```

### Variability
Variability (or dispersion) in statistics is concerned with the extent to which a distribution is spreaded out.

There exist various measures for variability and R has built-in functions for many of them:

* range: `min()`, `max()`, `range()`
* percentiles: `fivenum()`, `IQR()`, `quantile()`
* variance: `var()`, `sd()`

#### Range
Range is the interval between the minium nad maximum values. R offers `min` for getting the minimum value, `max()` for the maximum value, and `range()` for the range. Each of functions has the `na.rm` argument, so make sure change its input as needed.

```{r}
min(ispcrime$violentCrime, na.rm = TRUE)
max(ispcrime$violentCrime, na.rm = TRUE)
range(ispcrime$violentCrime, na.rm = TRUE)
```


#### Percentiles
R has a few useful functions to inspect the distribution of numerical data in terms of percentiles.

The `fivenum()` function returns what is called Tukey's five number summary (minumum, 1st quartile, median, 3rd qurtile, maximum) for the input data. `IQR()` returns the inter-quartile range, which is the difference between the 1st quartile (25%) and 3rd quartile (75%).

The following shows the outputs of these functions using `violentCrime` as the input:
```{r}
fivenum(ispcrime$violentCrime, na.rm = TRUE)
IQR(ispcrime$violentCrime, na.rm = TRUE)
```

`quntile()` is a somewhat more flexible function. The default setting output of `quantile()` is equal to `fivenum()` output. However, `quantile()` can use `probs` arugment to get more flexible output.
```{r}
# default: equal to fivenum()
quantile(ispcrime$violentCrime, probs = seq(0, 1, 0.25), na.rm = TRUE)
quantile(ispcrime$violentCrime, probs = seq(0, 1, 0.1), na.rm = TRUE)
```

#### Variance

The R function for variance is `var()`, which returns the sample variance of the given data:
$$s^2 = (\sum{x - \bar{x}}^2)/(n-1)$$

```{r}
var(ispcrime$violentCrime, na.rm = TRUE)
```

Similarly, `sd()` returns the standard deviation of the given data:
$$s = \sqrt{(\sum{x - \bar{x}}^2)/(n-1)}$$
```{r}
sd(ispcrime$violentCrime, na.rm = TRUE)
```

Note that `var()` returns a covariance matrix when multiple variables are given as its input. In such cases, another function named `cov()` can be used instead for clarity; however, `cov()` has no `na.rm` argument to handle missing values.

```{r}
variables <- ispcrime %>% select(violentCrime, propertyCrime)
var(variables, na.rm = TRUE)
```

### Shape

The skewness and kurtosis (fatness/thinness) of a distribution are called the "shape" of the distribution.

While base R has no functions to get these statistics (which are rarely used for common descriptive statistics anyway), the `moments` package offers the following functions to meaasure the shape of a distribution:

* `skewness()`
* `kurtosis()`

See `moments` package's [reference manual](https://cran.r-project.org/web/packages/moments/moments.pdf) to find out more.

### Outliers

Outliers are observations or data points that are far from most other observations and disproportinately affect key summary statistics

The `outliers` package offers useful functions to detect and measure outliers in data. See `outliers` package's  [reference manual](https://cran.r-project.org/web/packages/outliers/outliers.pdf) to learn more.


## Categorical variables
Inspecting the distribution of a categorical variable requires a different set of tools. Frequency table is one of the most common ways to summarize the distribution of a catagorical variable.

In R, frequency tables can be made using table functions. We will take a look at the following:

* `table()` for generating frequency tables
* `prop.table()` for tables of proportions
* `xtabs()` for creating frequency tables using formula
* `ftable()` for creating "flat" contingency tables

### Table functions
```{r eval=FALSE}
table(...)
prop.table(x, margin = NULL)
ftable(x)
xtabs(formula, data, ...)
```
`table()` takes one or more data vectors of same length. Each input data can be named like in the case of creating a `list` or a `data.frame` object. We can use `as.data.frame()` to turn a `table` into a data frame.

Both `prop.table()` and `ftable()` takes a `table` object. `prop.table()` returns a table in terms of proportion, where $0 \leq p \leq 1$ for each value. `ftable()` returns a `flat` contingency table. We will shorty see what this means with an example below.

Finally, `xtabs` use formula to generate a frequency table. If a data frame is provided as the `data` input, its column names can be used directly in formula.

### `table()` example
First, let us create a data to use for creating tables:
```{r}
my_data <- ispcrime %>%
  left_join(regions) %>%
  select(
    region,
    viol = violentCrime,
    prop = propertyCrime
  ) %>%
  mutate(
    high_viol = ifelse(viol > mean(viol, na.rm = TRUE), 1, 0),
    high_prop = ifelse(prop > mean(prop, na.rm = TRUE), 1, 0)
  )
```

Now, we create a `table` object with two dimensions: `region` for regions in the state, and `hviol` for the greater-than-average violent crime count.  
```{r}
my_tbl <- table(
  region = my_data$region,
  hviol = my_data$high_viol
)
```

Now we print the table.
```{r}
my_tbl
```

We can turn it into a `data.frame`, which can be more easily manipulated.
```{r}
as.data.frame(my_tbl)
```

### `prop.table()` example
`prop.table()` has a `margin` argument to control how to generate margin for. `magin` takes an index, or vector of indices as an input. Take a look at the following examples to see how `margin` argument works:
```{r}
prop.table(my_tbl, 1) # each row adds up to 1 
prop.table(my_tbl, 2) # each column adds up to 1
```
If `margin` input is `r NULL`, each cell is `x/sum(x)`.

### `ftable()` example
To better illustrate what `ftable()` does, we first create a table with three dimensions. This is becuase using `ftable()` for a table of 2 dimensions or less makes little difference.
```{r}
my_tbl2 <- table(
  region = my_data$region,
  hviol = my_data$high_viol,
  hprop = my_data$high_prop
)
```

Now, we first see the `ftable()` output.
```{r}
# with ftable
ftable(my_tbl2)
```

Then compare it to the default printing otuput.
```{r}
# without ftable
my_tbl2
```

### `xtabs()` example
`xtabs()` creates an `xtabs` object, which is built on top of `table`. Creating one-dimensional table with `xtabs()` looks like the following:
```{r}
# one-dimension
xtabs(~ region, my_data)
```

Adding more dimensions can be done usign the `+` operator in the formula:
```{r}
# two-dimension
xtabs(~ region + high_viol, my_data)
```


***


# Basic Inferential Statistics
```{r echo=FALSE, out.width="50%", out.extra='style="display: block; margin: auto; box-shadow: none;"'}
include_graphics("../images/vadlo_inferential_statistics.gif")
```
<p style="font-size:0.5em; text-align:center; color: #777;">
Source: <a href="http://vadlo.com/cartoons.php?id=407">Vadlo.com</a>
</p>


## Student's t-test
```{r eval=FALSE}
t.test(x, y = NULL, alternative = c("two.sided", "less", "greater"),
       mu = 0, conf.level = 0.95, ...)
t.test(formula, data, subset, na.action, ...)
```
* The null hypothesis assumes normal distribution
* The tested null hypothesis is no difference in mean and the alternative hypothesis can one of the three options, with the default of "two.sided"
* One sample t-test is conducted with only `x` input is given
    * The mean of `x` is compared against the `mu` value (default 0)
* Two sample t-test can be conducted by either supplying `x` and `y` inputs or using `formula` (`y ~ x`) with `data` input


```{r}
ispcrime2 <- left_join(ispcrime, regions)
viol_crime_north <- (filter(ispcrime2, region == "Northern"))$violentCrime
viol_crime_south <- (filter(ispcrime2, region == "Southern"))$violentCrime
t.test(viol_crime_north, viol_crime_south)
```

## Wilcox tests
```{r eval=FALSE}
wilcox.test(x, y = NULL, alternative = c("two.sided", "less", "greater"),
            mu = 0, conf.level = 0.95, ...)
wilcox.test(formula, data, subset, na.action, ...)
```
* The null hypothesis does NOT assume normality
* One sample Wilcox test (rank-sum test) is conducted with only `x` input is provided
* Two sample Wilcox test (singed-rank test) can be conducted by either supplying `x` and `y` inputs or using `formula` (`y ~ x`) with `data` input

## Analysis of Variance
```{r eval=FALSE}
aov(formula, data, qr = TRUE, ...)
```
* `formula` is of the following format: `value ~ subgroup`
* `summary()` has a method for `aov` class that returns a refined print result
* `model.tables()` has a method for `aov` class for reporting table of means or table of effects


```{r}
aov_by_region <- aov(formula = violentCrime ~ region, data = ispcrime2)
print(aov_by_region)
summary(aov_by_region)
```


```{r}
model.tables(aov_by_region, type = "means")
model.tables(aov_by_region, type = "effects")
```


## Other statistical tests
```{r eval=FALSE}
# Test of equal proprtions
prop.test(x, n, p, ...)

# Chi-square test of indepndence/goodness-of-fit
chisq.test(x, y = NULL, ...)

# Shapiro-Wilk test of normality
shapiro.test(x)

# One- or two-sample Kolmogorov-Smirnov test
ks.test(x, y, ..., alternative = "two.sided", exact = NULL)

# F-test to compare variances
var.test(x, y, ratio = 1, alternative = "two.sided",
         conf.level = 0.95, ...)
var.test(formula, data, subset, na.action, ...)

# Test of correlation between paired samples
cor.test(x, y, alternative = "two.sided", conf.level = 0.95,
         method = c("pearson", "kendell", "spearman"), ...)
```


***


# Linear models
<p style="font-size:1.5em">
$$y_i = \beta_0 + \beta_1 x_i + \varepsilon_i$$
$$\boldsymbol{\text{y}} = \boldsymbol{\text{X}}^{\text{T}}\boldsymbol{\beta} + \boldsymbol{\varepsilon}$$
</p>


## The lm() function
```{r eval=FALSE}
lm(formula, data, subset, na.action, ...)
```
* `lm()` is used to fit linear models, according to the `formula` input.
* `data` is an optional argument, which can take a data frame
    * If `data` input is provided, its column names can be used directly in the formula


## R formula
```{r eval=FALSE}
formula <- y ~ x1 + x2
```
* The response variable is placed on the left-hand side of the tilde symbol (`~`), and the explanatory variables on the right-hand side
    * Adding multiple explanatory variables can be done using `+` symbol
* Simply use `y ~ .` to include all other columns additively as explanatory variables


## Model summary
```{r eval=FALSE}
lmfit <- lm(formula, data)

print(lmfit) # not recommended
summary(lmfit)
```
* `lm()` output is an object of `lm` class
* Simply printing an `lm` object gives only minimal information on the fitted model
* `summary()` function with a model input (e.g. `lm`) prints a more comprehensive model summary


```{r}
my_lmfit <- lm(violentCrime ~ propertyCrime, ispcrime)
class(my_lmfit)
my_lmfit
```


```{r}
summary(my_lmfit)
```


## Model diagnostics
```{r eval=FALSE}
plot(lmfit, which = c(1:3, 5), ...)
```
* Base R `plot()` function has a method for `lm` objects
* `Total 6 plots are generated
    * "Residuals vs Fitted"
    * "Normal Q-Q"
    * "Scale-Location"
    * "Cook's distance"
    * "Residuals vs Leverage"
    * "Cook's dist vs Leverage $h_{ii}/(1-h_ii)$"

```{r fig.height=7, fig.width=8}
par(mfrow = c(2,3))
plot(my_lmfit, which = c(1:6))
```


## Model evaluation
```{r eval=FALSE}
logLik(object, ...)
AIC(object, ..., k = 2)
BIC(object, ...) # equivalent to AIC with k = log(n)
```
* There are measures of model fit other than $R^2$.
* For a model fitted by maximum likelihood algorithm:
    * `logLik()` for log-liklehood value
    * `AIC()` for Akaike Information Criterion (with default `k`)
    * `BIC()` for Bayesian Information Criterion
* Read [this Wikipedia article](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) for more on maximum likelihood estimation


## Extending lm() formula
* Transformations
* Interaction terms
* Polynomials
* Polynomial splines

### Transformations
```{r eval=FALSE}
scale(y) ~ log(x1) + sqrt(x2) + ...
```
* We can transform formula terms on either side of `~` by applying a function to each term
* Common transformations include:
    * `log()`: natural log (cf. `log2` and `log10`)
    * `exp()`: exponentiate
    * `sqrt()`: square root
    * `scale()`: rescale data such that the mean is 0 and the standard deviation is 1 

#### Transforming `x`
```{r echo=FALSE, fig.height=8}
x <- seq(1, 100, 2)
y <- seq(1, 100, 2)
par(mfrow = c(2, 2))
plot(x, y)
abline(a = 0, b = 1, col = "red")
plot(log(x), y)
abline(a = 0, b = 1, col = "red")
plot(sqrt(x), y)
abline(a = 0, b = 1, col = "red")
plot(exp(x), y)
abline(a = 0, b = 1, col = "red")
```

#### Transforming `y`
```{r echo=FALSE, fig.height=8}
par(mfrow = c(2, 2))
plot(x, y)
abline(a = 0, b = 1, col = "red")
plot(x, log(y))
abline(a = 0, b = 1, col = "red")
plot(x, sqrt(y))
abline(a = 0, b = 1, col = "red")
plot(x, exp(y))
abline(a = 0, b = 1, col = "red")
```

### Interactions
```{r eval=FALSE}
y ~ x1 + x2 + x1:x2
y ~ x1 * x2
```
* `x1:x2` takes the interactions of all terms in `x1` and `x2`
* `x1*x2` is equivalent to `x1:x2` *and* the original terms `x1` and `x2` 
* It is recommended to use an interaction term with all the original terms

### Polynomials
```{r eval=FALSE}
y ~ ploy(x, degree = n)
y ~ x + I(x^2) + I(x^3) + ...
```
* `poly()` generates the n-th degree polynimals of the input `x`
* `ploy(x, 3)` is equivalent to using `x + I(x^2) + I(x^3)`
    * `I()` ensures the `^` with a symbol is used as an arithmetic operator

### Polynomial splines
```{r eval=FALSE}
library(splines) # part of R "base pacakges"
y ~ ns(x, ...)
y ~ bs(x, degree = n, ...)
```
* `ns()` is used for the natural cubic splines
* `bs()` is used for the n-th degree polynomial splines
    * equivalent to `bs(x, degree = 3)`


## `broom` package
* `broom` is a `tidyverse` package for "tidying up" statistical model outputs in R, i.e., converting them into tidy data frames.
* `broom` functions:
  * `glance()`
  * `tidy()`
  * `augment()`
* Visit `broom` [GitHub repository](https://github.com/tidyverse/broom) and "`broom` as well as `dplyr`" [vignette](https://cran.r-project.org/web/packages/broom/vignettes/broom_and_dplyr.html) for more


### `broom` functions
```{r eval=FALSE}
glance(x, ...)
tidy(x, ...)
augment(x, ...)
```
* `glance()` takes a model object and returns a concise one-row summary of the model.
* `tidy()` takes a model object and returns a `data.frame` with the coeffcient estimation results
* `augment()` takes a model object and returns a `data.frame` for each observation with additional columns such as predictions, residuals and cluster assignments


```{r}
glance(my_lmfit)
tidy(my_lmfit)
# check the class of each output
c(class(glance(my_lmfit)), class(glance(my_lmfit)))
```


```{r}
head(augment(my_lmfit))
class(augment(my_lmfit))
```


## `modelr` package
* `modelr` is a `tidyverse` package that provides helper functions for statistical modeling in R
  * partitioning and sampling
  * model quality metrics
  * interacting with models
* Visit `modelr` [GitHub repository](https://github.com/tidyverse/modelr) and the ["Model Basics" chapter](http://r4ds.had.co.nz/model-basics.html) in *R for Data Science* for more

### Partitioning and sampling
```{r eval=FALSE}
resample(data, idx)
resample_partition(data, p)
bootstrap(data, n, id = ".id")
```

### Model quality metrics
```{r eval=FALSE}
rmse(model, data)
mae(model, data)
qae(model, data, probs = c(0.05, 0.25, 0.5, 0.75, 0.95))
rsquare(model, data)
```
* `rmse()` returns the root mean squared error
* `mae()` returns the mean abosolute error
* `qae()` returns quantiles of absolute error
* `rsquare()` returns the $R^2$ value, i.e. the variance of the predictions divided by the variance of the reponse

### Interacting with models
```{r eval=FALSE}
add_predictions(data, model, var = "pred")
add_residuals(data, model, var = "resid")
```
* `add_predictions()` adds a new column to a data frame for predicted values based on a model
* `add_residuals()` adds a new column to a data frame for residuals based on a model


```{r}
ispcrime_subset <- select(ispcrime, year:violentCrime, propertyCrime)
ispcrime_subset2 <- ispcrime_subset %>%
  add_predictions(my_lmfit) %>%
  add_residuals(my_lmfit)

head(ispcrime_subset2)
```


***


# Generalized linear models
<p style="font-size:1.5em">
$$\text{E}[\boldsymbol{\text{Y}}] = \mu = g^{-1}(\boldsymbol{\text{X}\beta})$$
$$\text{Var}[\boldsymbol{\text{Y}}] = \text{V}[\mu] = \text{V}[g^{-1}(\boldsymbol{\text{X}}\boldsymbol{\beta})]$$
</p>


## GLM basics
The generalized linear model (GLM) extends the linear model to fit response variables with error distribution other than a gaussian distribution.

Three components of GLM are:

* A probability distribution from the exponential family
* A linear predictor, $\eta = \boldsymbol{\text{X}\beta}$
* A link function $g$, such that $\text{E}[\boldsymbol{\text{Y}}] = \mu = g^{-1}(\eta)$

See [this Wikipedia article](https://en.wikipedia.org/wiki/Generalized_linear_model) for more on GLM and the model components.


## The glm() function
```{r eval=FALSE}
glm(formula, family = gaussian, data, ...)
```
R offers the `glm()` function to fit GLM models. `glm()` uses `formula` to specify the model. Then, it uses `family` input to specify the link function $g$. The default is `gaussian(link = "identity")`, which corresponds to the linear model.

`glm()` function returns a `glm` class object, which has a `summary()` method to inspect the model estimation results.

### `family` objects
The following table lists GLM `family` options available for `glm()`:
```{r echo=FALSE}
kable(
  tribble(
    ~`family`, ~"Default link function", ~Use,
    "`gaussian`","`(link = \"identity\")`", "Linear model for continous outcome<br>(ordinary linear regression; OLS)",
    "`binomial`","`(link = \"logit\")`", "Logit model for binary outcome<br>(logistic regression)",
    "`poisson`","`(link = \"log\"`)", "Poisson model for count outcome",
    "`Gamma`","`(link = \"inverse\")`", "...",
    "`inverse.gaussian`","`(link = \"1/mu^2\")`", "...",
    "`quasi`", "`(link = \"identitiy\")`", "...",
    "`quasibinomial`", "`(link = \"logit\")`", "...",
    "`quasipoisson`", "`(link = \"log\")`", "..."
  )
)
```

### Logit model
```{r eval=FALSE}
glm(formula, family = binomial, data, ...)
```
A logit model, i.e. logistic regression, can be fitted using `glm()` with `family = binomial`. The response variable must range between 0 and 1 (an error will be thrown otherwise).

### Poisson model
```{r eval=FALSE}
glm(formula, family = poisson, data, ...)
```
A possion model can be fitted using `glm()` with `family = poisson`. Here, the response variable must not include negative values (an error will be thrown otherwise).


## Better ways?
There are thrid-party packages to provide additional fuctions and/or different interfaces to existing statistical analysis functions. Although I have little exposure to them, the following two might be worth checking:

* `psych` package. See [this package vignette](https://cran.r-project.org/web/packages/psych/vignettes/intro.pdf) by the package author to learn more about it.

* `jmv` package. See [this package documentation page](https://www.jamovi.org/jmv/) to learn more about it.


## Resources

Just as in any previous work module parts, what we have seen in this part is only an introduction tot he topic. The following are some useful resources that would help you to deepen your understanding of the basic statistics in R.

* Kabacoff, R. ["Statistics"](https://www.statmethods.net/stats/index.html). *Quick-R*.
* Lane D. et al. [*Online Statistics: A Multimedia Course of Study*](http://onlinestatbook.com/2/index.html).
* Prabhakaran, S. [r-statistics.co](http://r-statistics.co/).
* UCLA Institute for Digital Research and Education. ["R"](https://stats.idre.ucla.edu/r/).
* University of Cincinnati. ["Descriptive analytics"](http://uc-r.github.io/descriptive). *UC Business Analytic R Programming Guide*.
* University of Cincinnati. ["Predictive analytics"](http://uc-r.github.io/predictive). *UC Business Analytic R Programming Guide*.
* Wollschlaeger, D. [*RExRepos*](http://dwoll.de/rexrepos/index.html).
* Yau, C. ["Elementary Statistics with R"](http://www.r-tutor.com/elementary-statistics). *R Tutorial*.




***


# References
<ul>
  <li>Lane D. et al. (n.d.). <a href="http://onlinestatbook.com/2/index.html"><span style="font-style:italic">Online Statistics: A Multimedia Course of Study</span></a>.</li>
  <li>Prabhakaran, S. (n.d.). <a href="http://r-statistics.co/Statistical-Tests-in-R.html">"Statistic Tests"</a>. <i>r-statistics.co</i>.</li>
  <li><a href="https://github.com/tidyverse/broom">tidyverse/broom Github repository</a></li>
  <li><a href="https://github.com/tidyverse/modelr">tidyverse/modelr Github repository</a></li>
  <li>University of Cincinnati. <i><a href="http://uc-r.github.io/">UC Business Analytics R Programming Guide</a></i></li>
  <li>Wikipedia contributors. (2018). <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">"Generalized linear model"</a>. <i>Wikipedia, The Free Encyclopedia</i>.</li>
</ul>